{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d55fe-017d-4a1f-886c-e53678a16d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "from typing import Any, Dict, List\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as plt_an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a385749-c538-40e6-9d02-2d3b47935c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(x):\n",
    "    fs = 250\n",
    "    num_taps = 250\n",
    "    band = [1, 40]\n",
    "    trans_width = 0.5\n",
    "    edges = [\n",
    "        0, \n",
    "        band[0] - trans_width, \n",
    "        band[0], band[1],\n",
    "        band[1] + trans_width, \n",
    "        0.5*fs\n",
    "    ]    \n",
    "    b_taps = signal.remez(num_taps, edges, [0, 1, 0], fs=fs)\n",
    "    y = signal.filtfilt(b=b_taps, a=1, x=x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab419f1-b34d-43ca-9516-ecfc709a99ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'afdb'\n",
    "db_fs = 250\n",
    "db_path = os.path.join('..', 'db', db_name)\n",
    "asset_path = os.path.join('..', 'assets', db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefd28f-2beb-4be1-bbeb-b05e7d807c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wfdb.dl_database(db_dir=db_name, dl_dir=db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7f169-6d76-4cf0-aada-3f79988ba2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ids = [\n",
    " '04015', '04043', '04048', '04126', '04746', '04908', '04936', '05091', \n",
    " '05121', '05261', '06426', '06453', '06995', '07162', '07859', '07879', \n",
    " '07910', '08215', '08219', '08378', '08405', '08434', '08455'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b88747-0b22-4ed3-9090-8937e30b8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(pt_ids)\n",
    "split_idx = int(0.8*len(pt_ids))\n",
    "train_pt_ids = pt_ids[0:split_idx]\n",
    "test_pt_ids = pt_ids[split_idx:]\n",
    "print(train_pt_ids, test_pt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df805bc8-164c-4636-9589-0a319a3c2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_nm_segs = dict()\n",
    "pts_af_segs = dict()\n",
    "for pt_id in pt_ids:\n",
    "    dat, hdr = wfdb.rdsamp(os.path.join(db_path, pt_id))\n",
    "    atr = wfdb.rdann(os.path.join(db_path, pt_id), extension='atr')\n",
    "    samples = atr.sample.tolist()+[dat.shape[0]] # Need to append end index\n",
    "    pts_nm_segs[pt_id] = [(samples[i], samples[i+1]) for i, sym in enumerate(atr.aux_note) if 'N' in sym]\n",
    "    pts_af_segs[pt_id] = [(samples[i], samples[i+1]) for i, sym in enumerate(atr.aux_note) if 'AF' in sym]    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fde0df-35de-4d51-b75d-6c07d4b1e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt_id, segs in pts_af_segs.items():\n",
    "    pt_sum = 0\n",
    "    for seg in segs:\n",
    "        pt_sum += (seg[1] - seg[0])/db_fs\n",
    "    print(pt_id, round(pt_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4e5df-a44c-4731-97e1-7903603bb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pt_data(pt_id):\n",
    "    psd_len = 250\n",
    "    psd_gap = 30\n",
    "\n",
    "    sample_duration = 4.8 # should equate to 30 pixels\n",
    "    freq_limit = 33 # should equate to 30 pixels\n",
    "\n",
    "    t_width = round((sample_duration*db_fs-psd_len)/psd_gap)\n",
    "\n",
    "    nm_data = []\n",
    "    af_data = []\n",
    "    \n",
    "    # Get patient data\n",
    "    dat, hdr = wfdb.rdsamp(os.path.join(db_path, pt_id))\n",
    "    atr = wfdb.rdann(os.path.join(db_path, pt_id), extension='atr')\n",
    "    # Bandpass filter (0,0.5), (1, 40), (40.5, Fs)\n",
    "    ecg = bandpass(dat[:, 0])\n",
    "\n",
    "    # Extract Normal and AF segments\n",
    "    samples = atr.sample.tolist()+[dat.shape[0]] # Need to append end index\n",
    "    nm_segs = [(samples[i], samples[i+1]) for i, sym in enumerate(atr.aux_note) if 'N' in sym]\n",
    "    af_segs = [(samples[i], samples[i+1]) for i, sym in enumerate(atr.aux_note) if 'AF' in sym]\n",
    "    \n",
    "    f, t, sxx = signal.spectrogram(ecg, mode='psd', fs=db_fs, nperseg=psd_len, noverlap=psd_len-psd_gap)\n",
    "    max_f_idx = np.where(f < freq_limit)[0][-1]\n",
    "    for seg in nm_segs:\n",
    "        l_idx = int(np.ceil((seg[0] - 0)/psd_gap))\n",
    "        r_idx = int(np.floor((seg[1] - 0)/psd_gap))\n",
    "        for i in range(l_idx, r_idx-4*t_width+1, 4*t_width):\n",
    "            nm_data.append(sxx[:max_f_idx, i:i+t_width])\n",
    "\n",
    "    for seg in af_segs:\n",
    "        l_idx = int(np.ceil((seg[0] - 0)/psd_gap))\n",
    "        r_idx = int(np.floor((seg[1] - 0)/psd_gap))\n",
    "        for i in range(l_idx, r_idx-4*t_width+1, 4*t_width):\n",
    "            af_data.append(sxx[:max_f_idx, i:i+t_width])\n",
    "    \n",
    "    return nm_data, af_data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459319eb-9111-4a49-b15c-0c4b92d7e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nm_data = []\n",
    "train_af_data = []\n",
    "test_nm_data = []\n",
    "test_af_data = []\n",
    "\n",
    "for pt_id in train_pt_ids:\n",
    "    pt_nm_data, pt_af_data = generate_pt_data(pt_id)\n",
    "    train_nm_data += pt_nm_data\n",
    "    train_af_data += pt_af_data\n",
    "for pt_id in test_pt_ids:\n",
    "    pt_nm_data, pt_af_data = generate_pt_data(pt_id)\n",
    "    test_nm_data += pt_nm_data\n",
    "    test_af_data += pt_af_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba318ae-5bc5-4952-8e27-2308e88809d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_af_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddc8891-9850-4fe5-913a-d0881b045bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nm_data in enumerate(train_af_data[::50]):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
    "    ax.pcolormesh(nm_data, shading='gouraud', cmap='plasma') #, vmin=0.00005, vmax=.)\n",
    "    fig.savefig(f'/tmp/afdb/af/{i}.png')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0c4e3-5443-4703-9ee3-a5bf7d446d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nm_tensor = np.dstack(train_nm_data).transpose((2,0,1))\n",
    "train_af_tensor = np.dstack(train_af_data).transpose((2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99f583-3c3f-4605-9081-8a38ecb2ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nm_tensor = np.dstack(test_nm_data).transpose((2,0,1))\n",
    "test_af_tensor = np.dstack(test_af_data).transpose((2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029ceb7-e7cc-4b4c-b162-8004cae4a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((train_nm_tensor, train_af_tensor))\n",
    "y_train = np.concatenate((np.zeros(train_nm_tensor.shape[0]), np.ones(train_af_tensor.shape[0]))).astype(\"uint8\")\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce98ce9-35f1-484c-9bbc-b1f0618d2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.concatenate((test_nm_tensor, test_af_tensor))\n",
    "y_test = np.concatenate((np.zeros(test_nm_tensor.shape[0]), np.ones(test_af_tensor.shape[0]))).astype(\"uint8\")\n",
    "# Add a channels dimension\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d385e1-9d0a-49cd-9fd7-8d26ea2268a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.7, val_split=0.3, test_split=0.0, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    test_ds = ds.skip(train_size).take(val_size)\n",
    "    # test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbcfca-0b2d-4b93-981f-28ba11a8fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(10000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb95db-1332-4b45-a38d-d0c3a241d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ac8c7-8fef-4406-bd1a-76b516ed4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggCnn(Model):\n",
    "  def __init__(self):\n",
    "    super(VggCnn, self).__init__()\n",
    "    self.conv1 = Conv2D(50, 3, activation='relu')\n",
    "    self.batch = BatchNormalization()\n",
    "    self.flatten = Flatten()\n",
    "    self.drop1 = Dropout(0.3)\n",
    "    self.d1 = Dense(200, activation='relu')\n",
    "    self.drop2 = Dropout(0.3)\n",
    "    self.d2 = Dense(2)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = tf.image.per_image_standardization(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.batch(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.drop1(x)\n",
    "    x = self.d1(x)\n",
    "    x = self.drop2(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = VggCnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875db597-091f-4191-bb49-9cf3ea6d071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(32, 32, 1),\n",
    "    pooling=None,\n",
    "    classes=2,\n",
    "    classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70600912-b4f8-4878-adfb-49d14d18945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918830a-fb9a-47fa-927d-16edaa59043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98baeb64-7b06-4463-bd2f-921c9a6f7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258f4df-006d-4a43-988c-ed746d64a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb7e37-5476-4f90-bc0f-b54be6338d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb3f8a1-78b6-4f7f-b0f3-4561f5eed18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Loss: {test_loss.result()}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095215b5-546d-427a-b2f9-400d346845b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
    "elem = next(iter(test_ds))\n",
    "sxx = elem[0].numpy()[0,:,:,0].squeeze()\n",
    "lbl = elem[1].numpy()[0]\n",
    "print(lbl)\n",
    "ax.pcolormesh(sxx, shading='gouraud', cmap='plasma') #, vmin=0.00005, vmax=.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878ca99-0247-4179-a281-8a0e0693cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
    "ax.pcolormesh(af_tensor[9141], shading='gouraud', cmap='plasma') #, vmin=0.00005, vmax=.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134f7af-2cfc-41e8-bf6f-c5ebeef95f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, hdr = wfdb.rdsamp(os.path.join(db_path, pt_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973d534-0774-4814-b8a3-bfa3f5964ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "atr = wfdb.rdann(os.path.join(db_path, pt_id), extension='atr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba1e38-928e-420f-8f32-e344225b99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = atr.sample.tolist()+[dat.shape[0]]\n",
    "for i, sym in enumerate(atr.aux_note):\n",
    "    start = samples[i]\n",
    "    stop = samples[i+1]\n",
    "    print(sym, start, stop, (stop-start+1)/db_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbbe64-2e1c-4e40-942f-400c84d8e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bandpass(dat[:, 0])\n",
    "x1 = bandpass(dat[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fa154-909b-4eb6-a120-e0933bced137",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Sxx = signal.spectrogram(x, mode='psd', fs=250, nperseg=250, noverlap=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a8b23-4e0e-401f-aad3-aeff38f13094",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70aa14-c1c8-4075-8c17-96dffab8029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_start = int(1097510/25 - 30*25)\n",
    "# f_stop = f_start + 10*25\n",
    "# max_f_idx = np.where(f < 30)[0][-1]\n",
    "# y = Sxx[:max_f_idx, :]\n",
    "# fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(14, 8))\n",
    "# tax = ax[0].plot(x[0:500])\n",
    "# sax = ax[1].pcolormesh(y[:,f_start:f_stop], shading='gouraud', cmap='viridis', vmin=0.0005, vmax=.005)\n",
    "# def animate(frame, y):\n",
    "#     f_start = int(1097510/25 - 5*25) + 10*frame*25\n",
    "#     f_stop = f_start + 10*25 \n",
    "#     sax.set_array(y[:, f_start:f_stop])\n",
    "# anim = plt_an.FuncAnimation(fig, animate, fargs=(y, ), interval=50, frames=500)\n",
    "# anim.save('517.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2be091-0b67-4bb3-9bde-c41ffa22da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 133348 - 10*db_fs\n",
    "stop =  start + 20*db_fs\n",
    "\n",
    "f_start = int(start/30)\n",
    "f_stop = int(stop/30)\n",
    "print(f_start, f_stop, Sxx[:max_f_idx, f_start:f_stop].max())\n",
    "\n",
    "# f, t, Sxx = spectrogram(x[start:stop], mode='psd', fs=250, nperseg=250, noverlap=245)\n",
    "max_f_idx = np.where(f < 33)[0][-1]\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 12))\n",
    "ax[0].plot(x[start:stop])\n",
    "# ax[0].plot(x1[start:stop])\n",
    "# ax[0].plot(dat[start:stop, 0])\n",
    "ax[1].pcolormesh(t[f_start:f_stop], f[:max_f_idx], Sxx[:max_f_idx, f_start:f_stop], shading='gouraud', cmap='plasma') #, vmin=0.00005, vmax=.1)\n",
    "# ax[1].pcolormesh(t, f[:max_f_idx], Sxx2[:max_f_idx,:], shading='gouraud', cmap='viridis')\n",
    "# plt.ylabel('Frequency [Hz]')\n",
    "# plt.xlabel('Time [sec]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828b07b-ecb6-4746-955f-6982fc397a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sxx[:max_f_idx,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e466d9c-cad3-4ec4-ad3b-9f1f134705d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 716110 + 5*db_fs\n",
    "stop =  start + 5*db_fs\n",
    "\n",
    "f, t, Sxx = signal.spectrogram(x[start:stop], mode='psd', fs=250, nperseg=250, noverlap=125)\n",
    "max_f_idx = np.where(f < 30)[0][-1]\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(18, 10))\n",
    "ax[0].plot(x[start:stop])\n",
    "# ax[0].plot(x1[start:stop])\n",
    "# ax[0].plot(dat[start:stop, 0])\n",
    "ax[1].pcolormesh(t, f[:max_f_idx], Sxx[:max_f_idx,:], shading='gouraud', cmap='viridis', vmin=0, vmax=.005)\n",
    "# ax[1].pcolormesh(t, f[:max_f_idx], Sxx2[:max_f_idx,:], shading='gouraud', cmap='viridis')\n",
    "# plt.ylabel('Frequency [Hz]')\n",
    "# plt.xlabel('Time [sec]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb472f-bfa6-4e91-84ab-94a490aaf20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = signal.cwt(dat[start:stop, 0], signal.morlet2, np.arange(1, 16, 1))\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 12))\n",
    "ax[0].plot(dat[start:stop,1])\n",
    "ax[1].pcolormesh(np.abs(c), shading='gouraud', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07990626-fe78-4252-8a85-1c63e616db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.ricker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204374a8-85a7-48fd-b029-3f7090119052",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 119604 + int(250*.1)\n",
    "stop = start + 5*250\n",
    "f, t, Sxx = spectrogram(dat[start:stop,0], fs=250, nperseg=512, noverlap=511)\n",
    "\n",
    "max_f_idx = np.where(f < 20)[0][-1]\n",
    "plt.pcolormesh(t, f[:max_f_idx], Sxx[:max_f_idx,:], shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168920b1-277e-42c4-9e65-763c94f9e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f5b3a-a66f-44f1-a198-5627f42d75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55f2a3-cfcb-4e8b-b874-05e7c6bbd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9adfa-a619-4f13-aa07-8929d386b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbda65c-f24f-4cdc-b1b2-8c475dd65b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecf77c-4b64-4d46-bf4a-1db783356f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f757e63c5fa3fedb84a9906cb41d21074cb8f24bfcaee893ee1ad3884b734411"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
